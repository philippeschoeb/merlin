{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T20:55:28.623613Z",
     "start_time": "2025-06-12T20:55:28.574246Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import random\n",
    "\n",
    "import perceval as pcvl"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:55:33.812361Z",
     "start_time": "2025-06-12T20:55:33.781867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Simple Linear Model\n",
    "class LinearModelBaseline(nn.Module):\n",
    "    def __init__(self, input_size, num_classes=10):\n",
    "        super(LinearModelBaseline, self).__init__()\n",
    "        self.image_size = input_size\n",
    "\n",
    "        # Classical part\n",
    "        self.classifier = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Data is already flattened\n",
    "        output = self.classifier(x)\n",
    "        return output"
   ],
   "id": "e6410a106c26aca6",
   "outputs": [],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:20:24.928641Z",
     "start_time": "2025-06-12T20:19:56.055856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from merlin.datasets import mnist_digits\n",
    "\n",
    "def get_mnist_data(source=\"percevalquest\"):\n",
    "    \"\"\"\n",
    "    Get MNIST dataset. The returned images are flattened, scaled with MinMaxScaler and converted to torch.tensors.\n",
    "\n",
    "    Args:\n",
    "        source (str): [\"percevalquest\", \"full_dataset\"] Whether to return the percevalquest subset of the full dataset of MNIST\n",
    "\n",
    "    Returns:\n",
    "        X_train, y_train, X_test, y_test\n",
    "    \"\"\"\n",
    "    if source == \"percevalquest\":\n",
    "        train_features, train_labels, train_metadata = mnist_digits.get_data_train_percevalquest()\n",
    "        test_features, test_labels, test_metadata = mnist_digits.get_data_test_percevalquest()\n",
    "\n",
    "    elif source == \"full_dataset\":\n",
    "        # Define transform: convert images to tensors and normalize\n",
    "        transform = transforms.ToTensor()\n",
    "\n",
    "        # Download training data (60,000 samples)\n",
    "        train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "        # Separate images and labels\n",
    "        train_features = torch.stack([data[0] for data in train_dataset])  # shape: [60000, 1, 28, 28]\n",
    "        train_labels = torch.tensor([data[1] for data in train_dataset])  # shape: [60000]\n",
    "\n",
    "        # Download test data (10,000 samples)\n",
    "        test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "        test_features = torch.stack([data[0] for data in test_dataset])\n",
    "        test_labels = torch.tensor([data[1] for data in test_dataset])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown source: {source}\")\n",
    "\n",
    "    # Flatten the images from (N, 28, 28) to (N, 784)\n",
    "    train_features = train_features.reshape(train_features.shape[0], -1)\n",
    "    test_features = test_features.reshape(test_features.shape[0], -1)\n",
    "\n",
    "    # Scale\n",
    "    scaler = MinMaxScaler()\n",
    "    train_features = scaler.fit_transform(train_features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train = torch.FloatTensor(train_features)\n",
    "    y_train = torch.LongTensor(train_labels)\n",
    "    X_test = torch.FloatTensor(test_features)\n",
    "    y_test = torch.LongTensor(test_labels)\n",
    "\n",
    "    print(f\"Dataset loaded: {len(X_train)} training samples, {len(X_test)} test samples\")\n",
    "    print(f\"Train dataset shape : {X_train.shape}\")\n",
    "    print(f\"Train label shape : {y_train.shape}\")\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "source = \"full_dataset\"  # [\"percevalquest\", \"full_dataset\"]\n",
    "X_train, y_train, X_test, y_test = get_mnist_data(source)"
   ],
   "id": "8d6946db7c3c30a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 60000 training samples, 10000 test samples\n",
      "Train dataset shape : torch.Size([60000, 784])\n",
      "Train label shape : torch.Size([60000])\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:59:28.967745Z",
     "start_time": "2025-06-12T20:59:28.917041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Important hyperparameters\n",
    "M=16\n",
    "N=3\n",
    "n_components=M-1"
   ],
   "id": "903131b00f4148bf",
   "outputs": [],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:01:33.869290Z",
     "start_time": "2025-06-12T21:01:30.604539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train PCA\n",
    "def train_pca(X_train, X_test):\n",
    "    pca = PCA(n_components=n_components)\n",
    "\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = torch.FloatTensor(pca.transform(X_train))\n",
    "    X_test_pca = torch.FloatTensor(pca.transform(X_test))\n",
    "\n",
    "    # Compute min and max from the training set\n",
    "    min_val = X_train_pca.min()\n",
    "    max_val = X_train_pca.max()\n",
    "\n",
    "    # Avoid division by zero if max == min\n",
    "    if max_val == min_val:\n",
    "        raise ValueError(\"Cannot scale: all values in X_train_pca are the same.\")\n",
    "\n",
    "    # Scale both train and test using training set stats so they range between 0 and 1\n",
    "    X_train_pca = (X_train_pca - min_val) / (max_val - min_val)\n",
    "    X_test_pca = (X_test_pca - min_val) / (max_val - min_val)\n",
    "\n",
    "    print(X_train_pca)\n",
    "    print(X_train_pca.shape)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "X_train_pca, X_test_pca = train_pca(X_train, X_test)"
   ],
   "id": "d9f7badcf9abecb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4322, 0.4800, 0.4069,  ..., 0.4295, 0.5907, 0.3451],\n",
      "        [0.6573, 0.4755, 0.2495,  ..., 0.4817, 0.4238, 0.4610],\n",
      "        [0.3876, 0.3013, 0.4485,  ..., 0.3533, 0.4284, 0.4374],\n",
      "        ...,\n",
      "        [0.3556, 0.3601, 0.4661,  ..., 0.3589, 0.4295, 0.3065],\n",
      "        [0.4338, 0.4021, 0.2704,  ..., 0.5083, 0.3800, 0.3305],\n",
      "        [0.3567, 0.4070, 0.2597,  ..., 0.3449, 0.3277, 0.3550]])\n",
      "torch.Size([60000, 15])\n"
     ]
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:02:08.822879Z",
     "start_time": "2025-06-12T21:02:08.686689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_left_and_right_circuits(n_modes):\n",
    "    \"\"\"\n",
    "    Initialize random left and right side quantum circuits.\n",
    "    \"\"\"\n",
    "    left_side = pcvl.GenericInterferometer(n_modes,\n",
    "                            lambda idx: pcvl.BS(theta=np.pi*2*random.random()) // (0, pcvl.PS(phi=np.pi * 2 * random.random())),\n",
    "                            shape=pcvl.InterferometerShape.RECTANGLE,\n",
    "                            depth=2 * n_modes,\n",
    "                            phase_shifter_fun_gen=lambda idx: pcvl.PS(phi=np.pi*2*random.random()))\n",
    "    right_side = pcvl.GenericInterferometer(n_modes,\n",
    "                            lambda idx: pcvl.BS(theta=np.pi*2*random.random()) // (0, pcvl.PS(phi=np.pi * 2 * random.random())),\n",
    "                            shape=pcvl.InterferometerShape.RECTANGLE,\n",
    "                            depth=2 * n_modes,\n",
    "                            phase_shifter_fun_gen=lambda idx: pcvl.PS(phi=np.pi*2*random.random()))\n",
    "    return left_side, right_side\n",
    "\n",
    "left, right = initialize_left_and_right_circuits(M)"
   ],
   "id": "b9bc25b24fa1a490",
   "outputs": [],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:03:06.967660Z",
     "start_time": "2025-06-12T21:03:06.930634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_circuit(input_size, n_modes, left, right, scale=1, input=None):\n",
    "    \"\"\"\n",
    "    Create a quantum circuit.\n",
    "    \"\"\"\n",
    "    left_side = left\n",
    "\n",
    "    center = pcvl.Circuit(n_modes)\n",
    "    for i in range(input_size):\n",
    "        if input is None:\n",
    "            param = pcvl.P(f\"theta_{i}\")\n",
    "            center.add(i, pcvl.PS(phi=param))\n",
    "        else:\n",
    "            center.add(i, pcvl.PS(input[i] * scale))\n",
    "\n",
    "    right_side = right\n",
    "\n",
    "    circuit = pcvl.Circuit(n_modes)\n",
    "    circuit.add(0, left_side, merge=True)\n",
    "    circuit.add(0, center, merge=True)\n",
    "    circuit.add(0, right_side, merge=True)\n",
    "    return circuit\n",
    "\n",
    "def create_input_state(n_photons, n_modes, photons_at_start=True):\n",
    "    \"\"\"\n",
    "    Create a quantum input state.\n",
    "    \"\"\"\n",
    "    input_state = [0] * n_modes\n",
    "    i = 0\n",
    "    index = 0\n",
    "    while i < n_photons:\n",
    "        if photons_at_start:\n",
    "            input_state[i] = 1\n",
    "        else:\n",
    "            input_state[index] = 1\n",
    "\n",
    "        index += n_modes // n_photons\n",
    "        i += 1\n",
    "    print(f\"Input state : {input_state}\")\n",
    "    return input_state\n",
    "\n",
    "photons_at_start = False\n",
    "input_state = create_input_state(n_photons=N, n_modes=M, photons_at_start=photons_at_start)"
   ],
   "id": "3c65e3321fe2477e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input state : [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:03:44.668245Z",
     "start_time": "2025-06-12T21:03:44.646460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_quantum_output_proba(data, scale=1):\n",
    "    \"\"\"\n",
    "    Using Perceval, calculate the perfect output probability distributions out of the quantum circuit when sending in data in input.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): [Num_data, Num_PCA_components] Input data to the circuit\n",
    "        scale (float): Value to multiply each input value before encoding it into the circuit\n",
    "\n",
    "    Returns:\n",
    "        output (torch.Tensor): [Num_data, Num_possible_output_states] Output probabilities of the quantum circuit\n",
    "    \"\"\"\n",
    "    circuit = create_circuit(input_size=M-1, n_modes=M, left=left, right=right, scale=scale)\n",
    "    local_p = pcvl.Processor(\"SLOS\", circuit)\n",
    "    local_p.with_input(pcvl.BasicState(input_state))\n",
    "    sampler = pcvl.algorithm.Sampler(local_p)\n",
    "    # Using the add_iteration_list method does not seem to accelerate the process\n",
    "    sampler.add_iteration_list([{\"circuit_params\": {f\"theta_{i}\": float(val) * float(scale) for i, val in enumerate(input)}} for input in data])\n",
    "    prob_dist = sampler.probs()\n",
    "    result_list = prob_dist[\"results_list\"]\n",
    "\n",
    "    output= []\n",
    "    for r in result_list:\n",
    "        result = r[\"results\"]\n",
    "        vector = []\n",
    "        for state, value in result.items():\n",
    "            vector.append(value)\n",
    "        assert np.isclose(np.sum(vector), 1), f\"Sum of vector is not 1, {np.sum(vector)} != 1\"\n",
    "\n",
    "        output.append(vector)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    print(output.shape)\n",
    "    return output"
   ],
   "id": "608381316749cb4a",
   "outputs": [],
   "execution_count": 102
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:03:41.400358Z",
     "start_time": "2025-06-12T21:03:41.358278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_quantum_output_sampling(data, n_sample, scale=1):\n",
    "    \"\"\"\n",
    "    Using Perceval, calculate approximate output probability distributions out of the quantum circuit when sending in data in input by sampling.\n",
    "\n",
    "    Args:\n",
    "        data (torch.Tensor): [Num_data, Num_PCA_components] Input data to the circuit\n",
    "        n_sample (int): Number of samples to generate\n",
    "        scale (float): Value to multiply each input value before encoding it into the circuit\n",
    "\n",
    "    Returns:\n",
    "        output (torch.Tensor): [Num_data, Num_possible_output_states] Output probabilities of the quantum circuit\n",
    "    \"\"\"\n",
    "    # Find all possible states and store them in \"possible_states\"\n",
    "    circuit = create_circuit(input_size=M-1, n_modes=M, left=left, right=right, scale=scale, input=data[0])\n",
    "    local_p = pcvl.Processor(\"SLOS\", circuit)\n",
    "    local_p.with_input(pcvl.BasicState(input_state))\n",
    "    sampler = pcvl.algorithm.Sampler(local_p)\n",
    "    prob_dist = sampler.probs()\n",
    "    results = prob_dist[\"results\"]\n",
    "    possible_states = []\n",
    "    for state, values in results.items():\n",
    "        possible_states.append(state)\n",
    "    possible_states = [str(state) for state in possible_states]\n",
    "\n",
    "    # Sample from distribution\n",
    "    circuit = create_circuit(input_size=M-1, n_modes=M, left=left, right=right, scale=scale)\n",
    "    local_p = pcvl.Processor(\"SLOS\", circuit)\n",
    "    local_p.with_input(pcvl.BasicState(input_state))\n",
    "    sampler = pcvl.algorithm.Sampler(local_p)\n",
    "\n",
    "    # Using the add_iteration_list method does not seem to accelerate the process\n",
    "    sampler.add_iteration_list([{\"circuit_params\": {f\"theta_{i}\": float(val) * float(scale) for i, val in enumerate(input)}} for input in data])\n",
    "    sample_count = sampler.sample_count(n_sample)\n",
    "    result_list = sample_count[\"results_list\"]\n",
    "\n",
    "    output= []\n",
    "    for r in result_list:\n",
    "        result = r[\"results\"]\n",
    "        total = 0\n",
    "        vector = [0] * len(possible_states)\n",
    "        for state, value in result.items():\n",
    "            index = possible_states.index(str(state))\n",
    "            vector[index] = value\n",
    "            total += value\n",
    "        vector = np.array(vector) / total\n",
    "        assert np.isclose(np.sum(vector), 1), f\"Sum of vector is not 1, {np.sum(vector)} != 1\"\n",
    "\n",
    "        output.append(vector)\n",
    "\n",
    "    output = torch.tensor(output)\n",
    "    print(output.shape)\n",
    "    return output"
   ],
   "id": "17b6fb0b7c233697",
   "outputs": [],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:27.559507Z",
     "start_time": "2025-06-12T21:03:49.630007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get quantum output probabilities\n",
    "scale = np.pi * 2\n",
    "n_sampling = 1e6\n",
    "train_output = get_quantum_output_proba(X_train_pca, n_sampling, scale=scale)\n",
    "test_output = get_quantum_output_proba(X_test_pca, n_sampling, scale=scale)"
   ],
   "id": "262c02d08e28162",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[103]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m scale = np.pi * \u001B[32m2\u001B[39m\n\u001B[32m      2\u001B[39m n_sampling = \u001B[32m1e6\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m train_output = \u001B[43mget_quantum_output_proba\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_sampling\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mscale\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m test_output = get_quantum_output_proba(X_test_pca, n_sampling, scale=scale)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[102]\u001B[39m\u001B[32m, line 8\u001B[39m, in \u001B[36mget_quantum_output_proba\u001B[39m\u001B[34m(data, n_sample, scale)\u001B[39m\n\u001B[32m      6\u001B[39m sampler = pcvl.algorithm.Sampler(local_p)\n\u001B[32m      7\u001B[39m sampler.add_iteration_list([{\u001B[33m\"\u001B[39m\u001B[33mcircuit_params\u001B[39m\u001B[33m\"\u001B[39m: {\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtheta_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m: \u001B[38;5;28mfloat\u001B[39m(val) * \u001B[38;5;28mfloat\u001B[39m(scale) \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28minput\u001B[39m)}} \u001B[38;5;28;01mfor\u001B[39;00m \u001B[38;5;28minput\u001B[39m \u001B[38;5;129;01min\u001B[39;00m data])\n\u001B[32m----> \u001B[39m\u001B[32m8\u001B[39m prob_dist = \u001B[43msampler\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      9\u001B[39m result_list = prob_dist[\u001B[33m\"\u001B[39m\u001B[33mresults_list\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m     11\u001B[39m output= []\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\runtime\\job.py:81\u001B[39m, in \u001B[36mJob.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs) -> \u001B[38;5;28mdict\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexecute_sync\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\runtime\\local_job.py:86\u001B[39m, in \u001B[36mLocalJob.execute_sync\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     84\u001B[39m \u001B[38;5;28mself\u001B[39m._delta_parameters[\u001B[33m'\u001B[39m\u001B[33mcommand\u001B[39m\u001B[33m'\u001B[39m][\u001B[33m'\u001B[39m\u001B[33mprogress_callback\u001B[39m\u001B[33m'\u001B[39m] = \u001B[38;5;28mself\u001B[39m._progress_cb\n\u001B[32m     85\u001B[39m \u001B[38;5;28mself\u001B[39m._handle_params(args, kwargs)\n\u001B[32m---> \u001B[39m\u001B[32m86\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_fn_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_delta_parameters\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mcommand\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     87\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.get_results()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\runtime\\local_job.py:96\u001B[39m, in \u001B[36mLocalJob._call_fn_safe\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     94\u001B[39m     \u001B[38;5;66;03m# it has already been called, calling it again to get more precise running time\u001B[39;00m\n\u001B[32m     95\u001B[39m     \u001B[38;5;28mself\u001B[39m._status.start_run()\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m     \u001B[38;5;28mself\u001B[39m._results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     97\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._cancel_requested:\n\u001B[32m     98\u001B[39m         \u001B[38;5;28mself\u001B[39m._status.stop_run(RunningStatus.CANCELED, \u001B[33m\"\u001B[39m\u001B[33mUser has canceled the job\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\algorithm\\sampler.py:230\u001B[39m, in \u001B[36mSampler._probs_iterate_locally\u001B[39m\u001B[34m(self, max_shots, progress_callback)\u001B[39m\n\u001B[32m    228\u001B[39m \u001B[38;5;28mself\u001B[39m._apply_iteration(default_it | it)\n\u001B[32m    229\u001B[39m precision = \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._max_shots \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mmin\u001B[39m(\u001B[32m1e-6\u001B[39m, \u001B[32m1\u001B[39m / \u001B[38;5;28mself\u001B[39m._max_shots)\n\u001B[32m--> \u001B[39m\u001B[32m230\u001B[39m results[\u001B[33m'\u001B[39m\u001B[33mresults_list\u001B[39m\u001B[33m'\u001B[39m].append(\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_processor\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprobs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprecision\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m    231\u001B[39m results[\u001B[33m'\u001B[39m\u001B[33mresults_list\u001B[39m\u001B[33m'\u001B[39m][-\u001B[32m1\u001B[39m][\u001B[33m'\u001B[39m\u001B[33miteration\u001B[39m\u001B[33m'\u001B[39m] = it\n\u001B[32m    232\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m progress_callback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\components\\processor.py:191\u001B[39m, in \u001B[36mProcessor.probs\u001B[39m\u001B[34m(self, precision, progress_callback)\u001B[39m\n\u001B[32m    189\u001B[39m     \u001B[38;5;28mself\u001B[39m._simulator = SimulatorFactory.build(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    190\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m191\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_simulator\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_circuit\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mlinear_circuit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mexperiment\u001B[49m\u001B[43m.\u001B[49m\u001B[43mis_unitary\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcomponents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcircuit_size\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    192\u001B[39m     \u001B[38;5;28mself\u001B[39m._simulator.set_min_detected_photons_filter(\u001B[38;5;28mself\u001B[39m._min_detected_photons_filter)\n\u001B[32m    194\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m precision \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\simulators\\simulator.py:125\u001B[39m, in \u001B[36mSimulator.set_circuit\u001B[39m\u001B[34m(self, circuit, m)\u001B[39m\n\u001B[32m    118\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Set a circuit for simulation.\u001B[39;00m\n\u001B[32m    119\u001B[39m \n\u001B[32m    120\u001B[39m \u001B[33;03m:param circuit: a unitary circuit without polarized components\u001B[39;00m\n\u001B[32m    121\u001B[39m \u001B[33;03m:param m: The number of modes in the circuit. Only used in LC and TD simulators.\u001B[39;00m\n\u001B[32m    122\u001B[39m \u001B[33;03m If not provided, it is inferred from the modes of the components of the circuit list.\u001B[39;00m\n\u001B[32m    123\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    124\u001B[39m \u001B[38;5;28mself\u001B[39m._invalidate_cache()\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_backend\u001B[49m\u001B[43m.\u001B[49m\u001B[43mset_circuit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcircuit\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\backends\\_slos.py:139\u001B[39m, in \u001B[36mSLOSBackend.set_circuit\u001B[39m\u001B[34m(self, circuit)\u001B[39m\n\u001B[32m    137\u001B[39m \u001B[38;5;28mself\u001B[39m._input_state = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    138\u001B[39m \u001B[38;5;28mself\u001B[39m._circuit = circuit\n\u001B[32m--> \u001B[39m\u001B[32m139\u001B[39m \u001B[38;5;28mself\u001B[39m._umat = \u001B[43mcircuit\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute_unitary\u001B[49m\u001B[43m(\u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_symb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    140\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._path_roots \u001B[38;5;129;01mand\u001B[39;00m previous_circuit.m == circuit.m:\n\u001B[32m    141\u001B[39m     \u001B[38;5;66;03m# Use the previously deployed paths to store the new circuit's coefs\u001B[39;00m\n\u001B[32m    142\u001B[39m     get_logger().debug(\u001B[33m\"\u001B[39m\u001B[33mSLOS: compute coefficients keeping the previous path\u001B[39m\u001B[33m\"\u001B[39m, channel.general)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\components\\linear_circuit.py:503\u001B[39m, in \u001B[36mCircuit.compute_unitary\u001B[39m\u001B[34m(self, use_symbolic, assign, use_polarization)\u001B[39m\n\u001B[32m    501\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_polarization:\n\u001B[32m    502\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.requires_polarization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mpolarized circuit cannot generates non-polarized unitary\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m503\u001B[39m u = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_compute_circuit_unitary\u001B[49m\u001B[43m(\u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_polarization\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m u \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    505\u001B[39m     u = Matrix.eye(\u001B[38;5;28mself\u001B[39m._m, use_symbolic=use_symbolic)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\components\\linear_circuit.py:454\u001B[39m, in \u001B[36mCircuit._compute_circuit_unitary\u001B[39m\u001B[34m(self, use_symbolic, use_polarization)\u001B[39m\n\u001B[32m    452\u001B[39m multiplier = \u001B[32m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_polarization \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m1\u001B[39m\n\u001B[32m    453\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m r, c \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._components:\n\u001B[32m--> \u001B[39m\u001B[32m454\u001B[39m     cU = \u001B[43mc\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute_unitary\u001B[49m\u001B[43m(\u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_polarization\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_polarization\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    455\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(r) != multiplier*\u001B[38;5;28mself\u001B[39m._m:\n\u001B[32m    456\u001B[39m         nU = Matrix.eye(multiplier*\u001B[38;5;28mself\u001B[39m._m, use_symbolic)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\components\\linear_circuit.py:503\u001B[39m, in \u001B[36mCircuit.compute_unitary\u001B[39m\u001B[34m(self, use_symbolic, assign, use_polarization)\u001B[39m\n\u001B[32m    501\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m use_polarization:\n\u001B[32m    502\u001B[39m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m.requires_polarization \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mpolarized circuit cannot generates non-polarized unitary\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m503\u001B[39m u = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_compute_circuit_unitary\u001B[49m\u001B[43m(\u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_polarization\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    504\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m u \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    505\u001B[39m     u = Matrix.eye(\u001B[38;5;28mself\u001B[39m._m, use_symbolic=use_symbolic)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\components\\linear_circuit.py:456\u001B[39m, in \u001B[36mCircuit._compute_circuit_unitary\u001B[39m\u001B[34m(self, use_symbolic, use_polarization)\u001B[39m\n\u001B[32m    454\u001B[39m cU = c.compute_unitary(use_symbolic=use_symbolic, use_polarization=use_polarization)\n\u001B[32m    455\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(r) != multiplier*\u001B[38;5;28mself\u001B[39m._m:\n\u001B[32m--> \u001B[39m\u001B[32m456\u001B[39m     nU = \u001B[43mMatrix\u001B[49m\u001B[43m.\u001B[49m\u001B[43meye\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmultiplier\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_m\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_symbolic\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    457\u001B[39m     nU[multiplier*r[\u001B[32m0\u001B[39m]:multiplier*(r[-\u001B[32m1\u001B[39m]+\u001B[32m1\u001B[39m), multiplier*r[\u001B[32m0\u001B[39m]:multiplier*(r[-\u001B[32m1\u001B[39m]+\u001B[32m1\u001B[39m)] = cU\n\u001B[32m    458\u001B[39m     cU = nU\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\perceval\\utils\\matrix.py:103\u001B[39m, in \u001B[36mMatrix.eye\u001B[39m\u001B[34m(n, use_symbolic)\u001B[39m\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m use_symbolic:\n\u001B[32m    102\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m MatrixS(sp.eye(n))\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m MatrixN(\u001B[43mnp\u001B[49m\u001B[43m.\u001B[49m\u001B[43meye\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mcomplex\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\merlin_github\\merlin\\.venv\\Lib\\site-packages\\numpy\\lib\\_twodim_base_impl.py:235\u001B[39m, in \u001B[36meye\u001B[39m\u001B[34m(N, M, k, dtype, order, device, like)\u001B[39m\n\u001B[32m    233\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m M \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    234\u001B[39m     M = N\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m m = \u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mM\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[43m=\u001B[49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    236\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m k >= M:\n\u001B[32m    237\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:49:17.253615Z",
     "start_time": "2025-06-12T20:49:16.801647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the ouptutprobability distributions\n",
    "train_file_path = f\"./complete_dataset_saved_probas/train_{N}_{M}_scale_{scale:.2f}.pt\"\n",
    "test_file_path = f\"./complete_dataset_saved_probas/test_{N}_{M}_scale_{scale:.2f}.pt\"\n",
    "torch.save(train_output, train_file_path)\n",
    "torch.save(test_output, test_file_path)"
   ],
   "id": "db6236b89ca6dc61",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:09:22.061981Z",
     "start_time": "2025-06-12T20:09:22.047852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_run_info(N, M, only_use_pca=False):\n",
    "    \"\"\" Helper to display information \"\"\"\n",
    "    s = \"#######################################################################################\\n\"\n",
    "    s += f\"N_M = {N}_{M}\\n\"\n",
    "    s += f\"only_use_pca = {only_use_pca}\\n\"\n",
    "    s += f\"scale_type = {scale}\\n\"\n",
    "    return s"
   ],
   "id": "abb493ddf3dd21c0",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:09:23.736109Z",
     "start_time": "2025-06-12T20:09:23.711852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_summary_metrics(history):\n",
    "    \"\"\" Helper to display metrics \"\"\"\n",
    "    linear_best_test_acc = max(history[\"linear\"][\"accuracy\"][\"test\"])\n",
    "    linear_best_test_acc_index = history[\"linear\"][\"accuracy\"][\"test\"].index(max(history[\"linear\"][\"accuracy\"][\"test\"]))\n",
    "    linear_train_acc = history[\"linear\"][\"accuracy\"][\"train\"][linear_best_test_acc_index]\n",
    "    s = f\"Linear best test accuracy: {linear_best_test_acc:.4f} and associated train accuracy {linear_train_acc:.4f} at epoch {linear_best_test_acc_index}\\n\"\n",
    "    return s"
   ],
   "id": "25d99578c5e76834",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:52:24.103421Z",
     "start_time": "2025-06-12T20:50:10.385061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(path_to_train, path_to_test, X_train, X_test, only_use_pca=False, balance_q_and_raw=False):\n",
    "    \"\"\"\n",
    "    Train linear model that takes quantum outputs as inputs for classification.\n",
    "\n",
    "    Args:\n",
    "        path_to_train (str): Path to the tensor training data\n",
    "        path_to_test (str): Path to the tensor testing data\n",
    "        X_train (torch.Tensor): Raw MNIST training data\n",
    "        X_test (torch.Tensor): Raw MNIST testing data\n",
    "\n",
    "        only_use_pca (bool): If true, only use the quantum outputs and ignore the raw MNIST data\n",
    "        balance_q_and_raw (bool): If true, balance the quantum outputs and the raw MNIST data with a custom-made normalization\n",
    "    \"\"\"\n",
    "    # Loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer AdaGrad\n",
    "    if only_use_pca:\n",
    "        linear_model = LinearModelBaseline(input_size=output.shape[1], num_classes=10)\n",
    "    else:\n",
    "        linear_model = LinearModelBaseline(input_size=X_train.shape[1] + output.shape[1], num_classes=10)\n",
    "    optimizer_linear = torch.optim.Adagrad(linear_model.parameters(), lr=0.05)\n",
    "\n",
    "    # Create DataLoader for batching\n",
    "    quantum_output_train = torch.load(path_to_train)\n",
    "    quantum_output_test = torch.load(path_to_test)\n",
    "\n",
    "    # Batch_size = 100\n",
    "    batch_size = 100\n",
    "\n",
    "    if only_use_pca:\n",
    "        train_dataset = torch.utils.data.TensorDataset(quantum_output_train, y_train)\n",
    "    else:\n",
    "        # Scale X_train and quantum_output_train so they have the same norm to balance importance\n",
    "        if balance_q_and_raw:\n",
    "            q_output_norm = torch.norm(quantum_output_train, dim=1)\n",
    "            raw_data_norm = torch.norm(X_train, dim=1)\n",
    "            quantum_output_train = quantum_output_train / q_output_norm.unsqueeze(1)\n",
    "            X_train = X_train / raw_data_norm.unsqueeze(1)\n",
    "\n",
    "            q_output_norm = torch.norm(quantum_output_test, dim=1)\n",
    "            raw_data_norm = torch.norm(X_test, dim=1)\n",
    "            quantum_output_test = quantum_output_test / q_output_norm.unsqueeze(1)\n",
    "            X_test = X_test / raw_data_norm.unsqueeze(1)\n",
    "\n",
    "        train_combined = torch.cat((X_train, quantum_output_train), dim=1)\n",
    "        print(train_combined.shape)\n",
    "        train_dataset = torch.utils.data.TensorDataset(train_combined, y_train)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 100\n",
    "\n",
    "    history = {\n",
    "          'linear': {'loss': [], 'accuracy': {'train': [], 'test': []}},\n",
    "          'epochs': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        running_loss_linear = 0.0\n",
    "\n",
    "        linear_model.train()\n",
    "\n",
    "        for i, (input, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Linear model - Forward and Backward pass\n",
    "            outputs = linear_model(input.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer_linear.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_linear.step()\n",
    "            running_loss_linear += loss.item()\n",
    "\n",
    "        avg_loss_linear = running_loss_linear/len(train_loader)\n",
    "        history['linear']['loss'].append(avg_loss_linear)\n",
    "        history['epochs'].append(epoch + 1)\n",
    "\n",
    "        linear_model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            if only_use_pca:\n",
    "                outputs = linear_model(quantum_output_train.float())\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                linear_train_accuracy = (predicted == y_train).sum().item() / y_train.size(0)\n",
    "\n",
    "                outputs = linear_model(quantum_output_test.float())\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                linear_test_accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "            else:\n",
    "                train_combined = torch.cat((X_train, quantum_output_train), dim=1)\n",
    "                outputs = linear_model(train_combined.float())\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                linear_train_accuracy = (predicted == y_train).sum().item() / y_train.size(0)\n",
    "\n",
    "                test_combined = torch.cat((X_test, quantum_output_test), dim=1)\n",
    "                outputs = linear_model(test_combined.float())\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                linear_test_accuracy = (predicted == y_test).sum().item() / y_test.size(0)\n",
    "\n",
    "        history['linear']['accuracy']['train'].append(linear_train_accuracy)\n",
    "        history['linear']['accuracy']['test'].append(linear_test_accuracy)\n",
    "\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}],\\nLOSS ------------ Linear: {avg_loss_linear:.4f}'+\n",
    "              f',\\nTRAIN ACCURACY -- Linear: {linear_train_accuracy:.4f},\\nTEST ACCURACY --- Linear: {linear_test_accuracy:.4f}\\n')\n",
    "\n",
    "    run_info = get_run_info(N, M, only_use_pca=only_use_pca)\n",
    "    print(run_info)\n",
    "\n",
    "    summary_metrics = get_summary_metrics(history)\n",
    "    print(summary_metrics)\n",
    "    return\n",
    "\n",
    "\n",
    "only_use_pca = False\n",
    "balance_q_and_raw = True\n",
    "train(train_file_path, test_file_path, X_train, X_test, only_use_pca=only_use_pca, balance_pca_and_raw=balance_q_and_raw)"
   ],
   "id": "8da9190eadaa2d0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1148])\n",
      "\n",
      "Epoch [1/100],\n",
      "LOSS ------------ Linear: 0.4881,\n",
      "TRAIN ACCURACY -- Linear: 0.9097,\n",
      "TEST ACCURACY --- Linear: 0.9139\n",
      "\n",
      "\n",
      "Epoch [2/100],\n",
      "LOSS ------------ Linear: 0.3230,\n",
      "TRAIN ACCURACY -- Linear: 0.9206,\n",
      "TEST ACCURACY --- Linear: 0.9229\n",
      "\n",
      "\n",
      "Epoch [3/100],\n",
      "LOSS ------------ Linear: 0.2892,\n",
      "TRAIN ACCURACY -- Linear: 0.9263,\n",
      "TEST ACCURACY --- Linear: 0.9274\n",
      "\n",
      "\n",
      "Epoch [4/100],\n",
      "LOSS ------------ Linear: 0.2707,\n",
      "TRAIN ACCURACY -- Linear: 0.9299,\n",
      "TEST ACCURACY --- Linear: 0.9301\n",
      "\n",
      "\n",
      "Epoch [5/100],\n",
      "LOSS ------------ Linear: 0.2582,\n",
      "TRAIN ACCURACY -- Linear: 0.9326,\n",
      "TEST ACCURACY --- Linear: 0.9326\n",
      "\n",
      "\n",
      "Epoch [6/100],\n",
      "LOSS ------------ Linear: 0.2491,\n",
      "TRAIN ACCURACY -- Linear: 0.9342,\n",
      "TEST ACCURACY --- Linear: 0.9353\n",
      "\n",
      "\n",
      "Epoch [7/100],\n",
      "LOSS ------------ Linear: 0.2419,\n",
      "TRAIN ACCURACY -- Linear: 0.9347,\n",
      "TEST ACCURACY --- Linear: 0.9363\n",
      "\n",
      "\n",
      "Epoch [8/100],\n",
      "LOSS ------------ Linear: 0.2362,\n",
      "TRAIN ACCURACY -- Linear: 0.9367,\n",
      "TEST ACCURACY --- Linear: 0.9379\n",
      "\n",
      "\n",
      "Epoch [9/100],\n",
      "LOSS ------------ Linear: 0.2312,\n",
      "TRAIN ACCURACY -- Linear: 0.9376,\n",
      "TEST ACCURACY --- Linear: 0.9386\n",
      "\n",
      "\n",
      "Epoch [10/100],\n",
      "LOSS ------------ Linear: 0.2271,\n",
      "TRAIN ACCURACY -- Linear: 0.9387,\n",
      "TEST ACCURACY --- Linear: 0.9397\n",
      "\n",
      "\n",
      "Epoch [11/100],\n",
      "LOSS ------------ Linear: 0.2234,\n",
      "TRAIN ACCURACY -- Linear: 0.9395,\n",
      "TEST ACCURACY --- Linear: 0.9397\n",
      "\n",
      "\n",
      "Epoch [12/100],\n",
      "LOSS ------------ Linear: 0.2203,\n",
      "TRAIN ACCURACY -- Linear: 0.9402,\n",
      "TEST ACCURACY --- Linear: 0.9399\n",
      "\n",
      "\n",
      "Epoch [13/100],\n",
      "LOSS ------------ Linear: 0.2173,\n",
      "TRAIN ACCURACY -- Linear: 0.9408,\n",
      "TEST ACCURACY --- Linear: 0.9406\n",
      "\n",
      "\n",
      "Epoch [14/100],\n",
      "LOSS ------------ Linear: 0.2148,\n",
      "TRAIN ACCURACY -- Linear: 0.9415,\n",
      "TEST ACCURACY --- Linear: 0.9413\n",
      "\n",
      "\n",
      "Epoch [15/100],\n",
      "LOSS ------------ Linear: 0.2125,\n",
      "TRAIN ACCURACY -- Linear: 0.9422,\n",
      "TEST ACCURACY --- Linear: 0.9421\n",
      "\n",
      "\n",
      "Epoch [16/100],\n",
      "LOSS ------------ Linear: 0.2103,\n",
      "TRAIN ACCURACY -- Linear: 0.9424,\n",
      "TEST ACCURACY --- Linear: 0.9419\n",
      "\n",
      "\n",
      "Epoch [17/100],\n",
      "LOSS ------------ Linear: 0.2083,\n",
      "TRAIN ACCURACY -- Linear: 0.9428,\n",
      "TEST ACCURACY --- Linear: 0.9431\n",
      "\n",
      "\n",
      "Epoch [18/100],\n",
      "LOSS ------------ Linear: 0.2065,\n",
      "TRAIN ACCURACY -- Linear: 0.9435,\n",
      "TEST ACCURACY --- Linear: 0.9430\n",
      "\n",
      "\n",
      "Epoch [19/100],\n",
      "LOSS ------------ Linear: 0.2048,\n",
      "TRAIN ACCURACY -- Linear: 0.9438,\n",
      "TEST ACCURACY --- Linear: 0.9430\n",
      "\n",
      "\n",
      "Epoch [20/100],\n",
      "LOSS ------------ Linear: 0.2032,\n",
      "TRAIN ACCURACY -- Linear: 0.9445,\n",
      "TEST ACCURACY --- Linear: 0.9445\n",
      "\n",
      "\n",
      "Epoch [21/100],\n",
      "LOSS ------------ Linear: 0.2017,\n",
      "TRAIN ACCURACY -- Linear: 0.9449,\n",
      "TEST ACCURACY --- Linear: 0.9446\n",
      "\n",
      "\n",
      "Epoch [22/100],\n",
      "LOSS ------------ Linear: 0.2003,\n",
      "TRAIN ACCURACY -- Linear: 0.9450,\n",
      "TEST ACCURACY --- Linear: 0.9444\n",
      "\n",
      "\n",
      "Epoch [23/100],\n",
      "LOSS ------------ Linear: 0.1989,\n",
      "TRAIN ACCURACY -- Linear: 0.9455,\n",
      "TEST ACCURACY --- Linear: 0.9449\n",
      "\n",
      "\n",
      "Epoch [24/100],\n",
      "LOSS ------------ Linear: 0.1977,\n",
      "TRAIN ACCURACY -- Linear: 0.9457,\n",
      "TEST ACCURACY --- Linear: 0.9459\n",
      "\n",
      "\n",
      "Epoch [25/100],\n",
      "LOSS ------------ Linear: 0.1964,\n",
      "TRAIN ACCURACY -- Linear: 0.9463,\n",
      "TEST ACCURACY --- Linear: 0.9458\n",
      "\n",
      "\n",
      "Epoch [26/100],\n",
      "LOSS ------------ Linear: 0.1954,\n",
      "TRAIN ACCURACY -- Linear: 0.9460,\n",
      "TEST ACCURACY --- Linear: 0.9455\n",
      "\n",
      "\n",
      "Epoch [27/100],\n",
      "LOSS ------------ Linear: 0.1943,\n",
      "TRAIN ACCURACY -- Linear: 0.9466,\n",
      "TEST ACCURACY --- Linear: 0.9454\n",
      "\n",
      "\n",
      "Epoch [28/100],\n",
      "LOSS ------------ Linear: 0.1932,\n",
      "TRAIN ACCURACY -- Linear: 0.9464,\n",
      "TEST ACCURACY --- Linear: 0.9459\n",
      "\n",
      "\n",
      "Epoch [29/100],\n",
      "LOSS ------------ Linear: 0.1923,\n",
      "TRAIN ACCURACY -- Linear: 0.9468,\n",
      "TEST ACCURACY --- Linear: 0.9460\n",
      "\n",
      "\n",
      "Epoch [30/100],\n",
      "LOSS ------------ Linear: 0.1913,\n",
      "TRAIN ACCURACY -- Linear: 0.9470,\n",
      "TEST ACCURACY --- Linear: 0.9464\n",
      "\n",
      "\n",
      "Epoch [31/100],\n",
      "LOSS ------------ Linear: 0.1904,\n",
      "TRAIN ACCURACY -- Linear: 0.9472,\n",
      "TEST ACCURACY --- Linear: 0.9461\n",
      "\n",
      "\n",
      "Epoch [32/100],\n",
      "LOSS ------------ Linear: 0.1896,\n",
      "TRAIN ACCURACY -- Linear: 0.9477,\n",
      "TEST ACCURACY --- Linear: 0.9461\n",
      "\n",
      "\n",
      "Epoch [33/100],\n",
      "LOSS ------------ Linear: 0.1887,\n",
      "TRAIN ACCURACY -- Linear: 0.9477,\n",
      "TEST ACCURACY --- Linear: 0.9467\n",
      "\n",
      "\n",
      "Epoch [34/100],\n",
      "LOSS ------------ Linear: 0.1879,\n",
      "TRAIN ACCURACY -- Linear: 0.9479,\n",
      "TEST ACCURACY --- Linear: 0.9465\n",
      "\n",
      "\n",
      "Epoch [35/100],\n",
      "LOSS ------------ Linear: 0.1871,\n",
      "TRAIN ACCURACY -- Linear: 0.9483,\n",
      "TEST ACCURACY --- Linear: 0.9470\n",
      "\n",
      "\n",
      "Epoch [36/100],\n",
      "LOSS ------------ Linear: 0.1864,\n",
      "TRAIN ACCURACY -- Linear: 0.9482,\n",
      "TEST ACCURACY --- Linear: 0.9474\n",
      "\n",
      "\n",
      "Epoch [37/100],\n",
      "LOSS ------------ Linear: 0.1856,\n",
      "TRAIN ACCURACY -- Linear: 0.9483,\n",
      "TEST ACCURACY --- Linear: 0.9474\n",
      "\n",
      "\n",
      "Epoch [38/100],\n",
      "LOSS ------------ Linear: 0.1849,\n",
      "TRAIN ACCURACY -- Linear: 0.9489,\n",
      "TEST ACCURACY --- Linear: 0.9471\n",
      "\n",
      "\n",
      "Epoch [39/100],\n",
      "LOSS ------------ Linear: 0.1843,\n",
      "TRAIN ACCURACY -- Linear: 0.9489,\n",
      "TEST ACCURACY --- Linear: 0.9468\n",
      "\n",
      "\n",
      "Epoch [40/100],\n",
      "LOSS ------------ Linear: 0.1836,\n",
      "TRAIN ACCURACY -- Linear: 0.9487,\n",
      "TEST ACCURACY --- Linear: 0.9478\n",
      "\n",
      "\n",
      "Epoch [41/100],\n",
      "LOSS ------------ Linear: 0.1830,\n",
      "TRAIN ACCURACY -- Linear: 0.9494,\n",
      "TEST ACCURACY --- Linear: 0.9476\n",
      "\n",
      "\n",
      "Epoch [42/100],\n",
      "LOSS ------------ Linear: 0.1823,\n",
      "TRAIN ACCURACY -- Linear: 0.9494,\n",
      "TEST ACCURACY --- Linear: 0.9480\n",
      "\n",
      "\n",
      "Epoch [43/100],\n",
      "LOSS ------------ Linear: 0.1817,\n",
      "TRAIN ACCURACY -- Linear: 0.9493,\n",
      "TEST ACCURACY --- Linear: 0.9480\n",
      "\n",
      "\n",
      "Epoch [44/100],\n",
      "LOSS ------------ Linear: 0.1812,\n",
      "TRAIN ACCURACY -- Linear: 0.9496,\n",
      "TEST ACCURACY --- Linear: 0.9482\n",
      "\n",
      "\n",
      "Epoch [45/100],\n",
      "LOSS ------------ Linear: 0.1806,\n",
      "TRAIN ACCURACY -- Linear: 0.9498,\n",
      "TEST ACCURACY --- Linear: 0.9478\n",
      "\n",
      "\n",
      "Epoch [46/100],\n",
      "LOSS ------------ Linear: 0.1800,\n",
      "TRAIN ACCURACY -- Linear: 0.9498,\n",
      "TEST ACCURACY --- Linear: 0.9479\n",
      "\n",
      "\n",
      "Epoch [47/100],\n",
      "LOSS ------------ Linear: 0.1795,\n",
      "TRAIN ACCURACY -- Linear: 0.9497,\n",
      "TEST ACCURACY --- Linear: 0.9473\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[92]\u001B[39m\u001B[32m, line 116\u001B[39m\n\u001B[32m    114\u001B[39m only_use_pca = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    115\u001B[39m balance_pca_and_raw = \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m116\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_file_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monly_use_pca\u001B[49m\u001B[43m=\u001B[49m\u001B[43monly_use_pca\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbalance_pca_and_raw\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbalance_pca_and_raw\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[92]\u001B[39m\u001B[32m, line 64\u001B[39m, in \u001B[36mtrain\u001B[39m\u001B[34m(path_to_train, path_to_test, X_train, X_test, only_use_pca, balance_pca_and_raw)\u001B[39m\n\u001B[32m     59\u001B[39m linear_model.train()\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i, (\u001B[38;5;28minput\u001B[39m, labels) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[32m     62\u001B[39m \n\u001B[32m     63\u001B[39m     \u001B[38;5;66;03m# Linear model - Forward and Backward pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m64\u001B[39m     outputs = linear_model(\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     65\u001B[39m     loss = criterion(outputs, labels)\n\u001B[32m     66\u001B[39m     optimizer_linear.zero_grad()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save the probability tensors to json format",
   "id": "95466bdcdb5f78b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T20:54:55.533424Z",
     "start_time": "2025-06-12T20:54:16.797153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the saved probability tensors to json format together\n",
    "import json\n",
    "Ns = [3]\n",
    "Ms = [12]\n",
    "scales = [2 * np.pi]\n",
    "\n",
    "data_dico = {}\n",
    "for M in Ms:\n",
    "    train_path = f\"./complete_dataset_saved_probas/train_{N}_{M}_scale_{scale:.2f}.pt\"\n",
    "    test_path = f\"./complete_dataset_saved_probas/test_{N}_{M}_scale_{scale:.2f}.pt\"\n",
    "\n",
    "    train_tensor = torch.load(train_path)\n",
    "    test_tensor = torch.load(test_path)\n",
    "    data_dico[M] = {\"train\": train_tensor.tolist(), \"test\": test_tensor.tolist()}\n",
    "\n",
    "with open(\"./complete_dataset_saved_probas/quantum reservoir saved probas.json\", \"w\") as f:\n",
    "    json.dump(data_dico, f)"
   ],
   "id": "9b44ff4b57116d66",
   "outputs": [],
   "execution_count": 93
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
